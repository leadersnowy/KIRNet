import torch
import torch.nn as nn
import torch.nn.functional as F

# =====================================================
# 全局配置
# =====================================================
# 治疗类型（离散）
treatments = ['化疗', '放疗', '手术治疗', '免疫治疗', '靶向治疗']

# 生理 / 生化指标（必须与数据列一一对应）
indicators = [
    'BMI', '收缩压', '舒张压', '葡萄糖', '胆固醇', 'LDL-C', '甘油三酯', 'HDL-C', 'D-二聚体', '血小板', '中性粒细胞','淋巴细胞','NLR（中性粒细胞/淋巴细胞）','神经元特异性烯醇化酶', '鳞状细胞癌相关抗原', '胃泌素释放肽前体', '细胞角蛋白19片段', 'CRP', '降钙素原', 'IL-6', 'BNP', '高敏肌钙蛋白T', '肾小球滤过率', '肌酐', '脂蛋白a', '游离三碘甲状腺原氨酸', '促甲状腺激素', '游离甲状腺素'
]


NUM_IND = len(indicators)
NUM_TREAT = len(treatments)

# 预测的离散时间区间（月）
TIME_BINS = [6, 12, 18, 24]

# =====================================================
# 生理指标图卷积模块（静态依赖）
# =====================================================
class PhysiologyGCN(nn.Module):
    """ 用固定的生理指标依赖图（adj）在指标维度上传播信息 """
    def __init__(self, embed_dim):
        super().__init__()
        self.fc1 = nn.Linear(embed_dim, embed_dim)
        self.fc2 = nn.Linear(embed_dim, embed_dim)

    def forward(self, x, adj):
        """ x : B × V × E （batch × 指标 × embedding）
        adj : V × V （指标依赖矩阵） """
        # 第一次传播
        h = torch.einsum("vw,bwe->bve", adj, x)
        h = F.relu(self.fc1(h))
        # 第二次传播（GCN 的多跳依赖）
        h = torch.einsum("vw,bwe->bve", adj, h)
        h = self.fc2(h)
        return h

# =====================================================
# 急性治疗效应模块
# =====================================================
class AcuteModule(nn.Module):
    """ 建模“最后一次治疗 → 当前预测时间”的短期（急性）影响 """
    def __init__(self):
        super().__init__()
        self.decay_rate = nn.Parameter(torch.tensor(0.05))  # 可学习衰减率
        # self.treat2id = {t: i for i, t in enumerate(treatments)}
        self.treat_effect = nn.Parameter(torch.FloatTensor([
            [-1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, -0.5, 1.0, -1.5, -1.0,-1.0,1.0,0.5, 0, 0, 0, 1.5, 1.0, 1.5, 1.5, 1.5, -1.0, 1.0, 0.5, 0, 0, 0],  # 化疗
            [-0.5, 0.5, 0.5, 0, -0.5, -0.5, 0.5, -0.5, 0.5, -0.5,0.5,-1.0,1.0,0, 0, 0, 0, 1.0, 0.5, 1.0, 0.5, 0.5, -0.5, 0.5, 0, -0.5, 0.5, -0.5],  # 放疗
            [-0.5, 1.0, 1.0, 0.5, 0, 0, 0, 0, 1.0, -0.5, 0.5,-0.5,0.5,0, 0, 0,0, 1.5, 0.5, 1.0, 0.5, 0.5, -0.5, 0.5, 0, 0, 0, 0],  # 手术治疗
            [-0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, -0.5, 1.0, -1.0, 0.5,0.5,1.0,0.5, 0, 0, 0, 1.5, 1.0, 1.5, 1.0, 1.5, -0.5, 0.5, 0.5, -0.5, 1.0, -0.5],  # 免疫治疗
            [0, 1.5, 1.5, 0.5, 1.0, 1.0, 0.5, -0.5, 0.5, -0.5, -0.5,-0.5,1.0,0,0, 0, 0, 1.0, 0.5, 1.0, 1.0, 1.0, -1.0, 1.0, 0.5, -1.0, 0.5, -1.0]  # 靶向治疗
        ]))
        self.treat_effect_expert = nn.Parameter(torch.FloatTensor([
            [-0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, -1.0, -1.0,-1.5,-1.5,1.0,0.0, 0.0, 0.0, 0.0, 0.5 , 0.0,0.5,0.0, 0.0, -0.5,0.5, 0.5,-0.5, 0.5, 0.5],  # 化疗
            [-0.5, 0.0, 0.0, 0.0, -0.5, -0.5, -0.5, 0.0, -1.0, -0.5, -1.5,-1.5,1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, -0.5, 0.5, 0.0, -0.5, 0.5, -0.5],  # 放疗
            [-0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, -0.5,1.5,-0.5,1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5, 0.0, 0.0], # 手术治疗
            [0.0, -0.5, -0.5, 0.0, 0.5, 0.5, 0.5, 0.5, -1.0, 0.0,0.5,0.5,-0.5, 0.0, 0.0, 0.0, 0.0, -0.5, 0.0, 0.5, -0.5, 0.0, -0.5, 0.5, 0.5, 0.0, 0.0, 0.0],  # 免疫治疗
            [0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, -1.0, 0.0,0.0,0.0,0.5,0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5, 0.5, 0.0, 0.0, 0.0, 0.0]  # 靶向治疗
        ]))

    def forward(self, treat_ids, delta_t):
        device = delta_t.device
        effect = self.treat_effect[treat_ids]*0.4+self.treat_effect_expert[treat_ids]*0.6 # B × V
        decay = torch.exp(-self.decay_rate * delta_t).unsqueeze(1)  # B × 1
        return effect * decay  # B × V

# =====================================================
# 累积治疗效应模块
# =====================================================
class CumulativeModule(nn.Module):
    """ 累积所有历史治疗事件的长期影响 （针对单个患者） """
    def __init__(self):
        super().__init__()
        self.decay_rate = nn.Parameter(torch.tensor(0.015))
        self.treat2id = {t: i for i, t in enumerate(treatments)}
        self.treat_effect = nn.Parameter(torch.FloatTensor([
            [-1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, -0.5, 1.0, -1.5, -1.0, -1.0, 1.0, 0.5, 0, 0, 0, 1.5, 1.0, 1.5, 1.5,1.5, -1.0, 1.0, 0.5, 0, 0, 0],  # 化疗
            [-0.5, 0.5, 0.5, 0, -0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -1.0, 1.0, 0, 0, 0, 0, 1.0, 0.5, 1.0, 0.5, 0.5,-0.5, 0.5, 0, -0.5, 0.5, -0.5],  # 放疗
            [-0.5, 1.0, 1.0, 0.5, 0, 0, 0, 0, 1.0, -0.5, 0.5, -0.5, 0.5, 0, 0, 0, 0, 1.5, 0.5, 1.0, 0.5, 0.5, -0.5, 0.5,0, 0, 0, 0],  # 手术治疗
            [-0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, -0.5, 1.0, -1.0, 0.5, 0.5, 1.0, 0.5, 0, 0, 0, 1.5, 1.0, 1.5, 1.0, 1.5,-0.5, 0.5, 0.5, -0.5, 1.0, -0.5],  # 免疫治疗
            [0, 1.5, 1.5, 0.5, 1.0, 1.0, 0.5, -0.5, 0.5, -0.5, -0.5, -0.5, 1.0, 0, 0, 0, 0, 1.0, 0.5, 1.0, 1.0, 1.0,-1.0, 1.0, 0.5, -1.0, 0.5, -1.0]  # 靶向治疗
        ]))
        self.treat_effect_expert = nn.Parameter(torch.FloatTensor([
            [-0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, -1.0, -1.0, -1.5, -1.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5,0.0, 0.0, -0.5, 0.5, 0.5, -0.5, 0.5, 0.5],  # 化疗
            [-0.5, 0.0, 0.0, 0.0, -0.5, -0.5, -0.5, 0.0, -1.0, -0.5, -1.5, -1.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, -0.5, 0.5, 0.0, -0.5, 0.5, -0.5],  # 放疗
            [-0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, -0.5, 1.5, -0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.0,0.0, 0.0, 0.0, 0.0, -0.5, 0.0, 0.0],  # 手术治疗
            [0.0, -0.5, -0.5, 0.0, 0.5, 0.5, 0.5, 0.5, -1.0, 0.0, 0.5, 0.5, -0.5, 0.0, 0.0, 0.0, 0.0, -0.5, 0.0, 0.5,-0.5, 0.0, -0.5, 0.5, 0.5, 0.0, 0.0, 0.0],  # 免疫治疗
            [0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, -1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,0.0, -0.5, 0.5, 0.0, 0.0, 0.0, 0.0]  # 靶向治疗
        ]))

    def forward(self, treat_events, current_time):
        device = current_time.device
        cum_effect = torch.zeros(NUM_IND, device=device)
        if len(treat_events) == 0:  # 空事件直接返回0
            return cum_effect
        for ev in treat_events:
            tid = self.treat2id.get(ev['type'], 0)
            effect = self.treat_effect[tid]*0.4+self.treat_effect_expert[tid]*0.6
            dt = (current_time - ev['time'])
            if torch.isnan(dt):
                dt = torch.tensor(0.0, device=current_time.device)
            dt = dt.clamp(min=0.0)
            decay = torch.exp(-self.decay_rate * dt)
            strength = ev.get('dose_ratio', 1.0) if ev.get('is_drug', False) else 1.0
            cum_effect += effect * decay * strength
        return cum_effect

# =====================================================
# 指标贡献度感知模块（可解释性）
# =====================================================
class IndicatorContribution(nn.Module):
    """ 学习每个生理指标对 TBR 的相对贡献（soft attention） """
    def __init__(self, embed_dim):
        super().__init__()
        self.score_net = nn.Linear(embed_dim, 1)

    def forward(self, phys_repr):
        """ phys_repr : B × V × E """
        scores = self.score_net(phys_repr).squeeze(-1)  # B × V
        weights = F.softmax(scores, dim=1)  # B × V
        pooled = torch.sum(weights.unsqueeze(-1) * phys_repr, dim=1)
        return pooled, weights

# =====================================================
# 条件 TBR 回归头（按时间区间）
# =====================================================
class TBRConditionalHead(nn.Module):
    """ 在不同时间区间下，学习不同的映射关系 """
    def __init__(self, embed_dim):
        super().__init__()
        self.time_embed = nn.Embedding(len(TIME_BINS), embed_dim)
        self.mlp = nn.Sequential(
            nn.Linear(embed_dim * 2, embed_dim),
            nn.ReLU(),
            nn.Linear(embed_dim, 1)
        )

    def forward(self, x, time_idx):
        """ x : B × E time_idx : B（0~3） """
        t_emb = self.time_embed(time_idx)
        return self.mlp(torch.cat([x, t_emb], dim=1)).squeeze(1)

# =====================================================
# 总体模型
# =====================================================
class TBRPredictionModel(nn.Module):
    def __init__(self, embed_dim=64):
        super().__init__()
        self.embed_dim = embed_dim

        # 生理指標編碼 + GCN（不變）
        self.phys_encoder = nn.Linear(1, embed_dim)
        self.phys_gcn = PhysiologyGCN(embed_dim)

        # 急性 + 累積模塊（不變）
        self.acute_module = AcuteModule()
        self.cum_module = CumulativeModule()

        # 時間嵌入（不變）
        self.time_encoder = nn.Sequential(
            nn.Linear(2, embed_dim // 2),
            nn.ReLU(),
            nn.Linear(embed_dim // 2, embed_dim)
        )

        # 治療事件嵌入（不變）
        self.treat_embedding = nn.Sequential(
            nn.Linear(NUM_TREAT, embed_dim // 2),
            nn.ReLU(),
            nn.Linear(embed_dim // 2, embed_dim)
        )

        # ───── 新增：輕量 self-attention pooling ─────
        self.attn_pool = IndicatorContribution(embed_dim)

        # 回歸頭（輸入仍是 embed_dim，因為 pooled 是 E 維）
        self.tbr_head = TBRConditionalHead(embed_dim)

        # 鄰接矩陣（不變）
        self.register_buffer('adj', self.build_adj())

    def build_adj(self):
        adj_data= [
            # 0: BMI
            [0, 3, 3, 3, 3, 3, 3, -3, 1, 1, 1, -1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, -1, 1, 3, -1, 1, -1],
            # 1: 收缩压
            [3, 0, 3, 1, 2, 2, 2, -1, 2, 1, 2, -1, 2, 1, 1, 1, 1, 2, 1, 2, 3, 2, -1, 2, 2, -1, 1, -1],
            # 2: 舒张压
            [3, 3, 0, 1, 2, 2, 2, -1, 2, 1, 2, -1, 2, 1, 1, 1, 1, 2, 1, 2, 3, 2, -1, 2, 2, -1, 1, -1],
            # 3: 血糖
            [3, 1, 1, 0, 3, 3, 3, -3, 2, 1, 2, -1, 2, 1, 1, 1, 1, 3, 1, 3, 2, 2, -1, 1, 3, -1, 1, -1],
            # 4: 总胆固醇
            [3, 2, 2, 3, 0, 3, 3, -1, 1, 1, 1, -1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, -1, 1, 3, -1, 1, -1],
            # 5: LDL-C
            [3, 2, 2, 3, 3, 0, 2, -1, 1, 1, 1, -1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, -1, 1, 3, -1, 1, -1],
            # 6: 甘油三酯
            [3, 2, 2, 3, 3, 2, 0, -3, 1, 1, 2, 0, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, -1, 1, 2, -1, 1, -1],
            # 7: HDL-C
            [-3, -1, -1, -3, -1, -1, -3, 0, -1, -1, -1, 0, -3, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1],
            # 8: D-二聚体
            [1, 2, 2, 2, 1, 1, 1, -1, 0, 2, 2, -1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, -1, 1, 1, -1, 1, -1],
            # 9: 血小板
            [1, 1, 1, 1, 1, 1, 1, -1, 2, 0, 1, -2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1],
            # 10: 中性粒细胞
            [1, 2, 2, 2, 1, 1, 2, -1, 2, 1, 0, -2, 3, 1, 1, 1, 1, 3, 2, 3, 2, 2, -1, 1, 1, -1, 1, -1],
            # 11: 淋巴细胞
            [-1, -1, -1, -1, -1, -1, 0, 0, -1, -2, -2, 0, -2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
            # 12: NLR（中性粒细胞/淋巴细胞）
            [2, 2, 2, 2, 2, 2, 2, -3, 2, 1, 3, -2, 0, 2, 2, 2, 2, 3, 3, 3, 2, 2, -3, 1, 2, -1, 1, -1],
            # 13: 神经元特异性烯醇化酶
            [1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 2, 0, 1, 2, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1],
            # 14: 鳞状细胞癌相关抗原
            [1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1],
            # 15: 胃泌素释放肽前体
            [1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1],
            # 16: 细胞角蛋白19片段
            [1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1],
            # 17: CRP
            [2, 2, 2, 3, 2, 2, 2, -1, 2, 1, 3, 1, 3, 1, 1, 1, 1, 0, 2, 3, 2, 3, -1, 1, 2, -1, 1, -1],
            # 18: 降钙素原
            [1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 2, 0, 3, 1, 1, 1, 1, 2, 0, 2, 1, 2, -1, 1, 1, -1, 1, -1],
            # 19: IL-6
            [2, 2, 2, 3, 2, 2, 2, -1, 2, 1, 3, 1, 3, 1, 1, 1, 1, 3, 2, 0, 2, 3, -1, 1, 2, -1, 1, -1],
            # 20: BNP
            [2, 3, 3, 2, 1, 1, 1, -1, 2, 1, 2, 0, 2, 1, 1, 1, 1, 2, 1, 2, 0, 3, -2, 2, 1, -1, 2, -1],
            # 21: 高敏肌钙蛋白T
            [2, 2, 2, 2, 1, 1, 1, -1, 2, 1, 2, 0, 2, 1, 1, 1, 1, 3, 2, 3, 3, 0, -2, 2, 1, -1, 2, -1],
            # 22: 肾小球滤过率 (eGFR)
            [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -3, -1, -1, -1, -1, -1, -1, -1, -2, -2, 0, -2, -1, 0, -1, 1],
            # 23: 肌酐
            [1, 2, 2, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, -2, 0, 1, -1, 1, -1],
            # 24: 脂蛋白(a)
            [3, 2, 2, 3, 3, 3, 2, -1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, -1, 1, 0, 0, 1, -1],
            # 25: 游离三碘甲状腺原氨酸 (FT3)
            [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, 0, -2, 3],
            # 26: 促甲状腺激素 (TSH)
            [1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, -1, 1, 1, -2, 0, -1],
            # 27: 游离甲状腺素 (FT4)
            [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 3, -1, 0]
        ]
        adj_data_expert = [
            # 1. BMI
            [0, 3, 3, 3, 2, 2, 3, -2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, 0, -1, 1, -2],
            # 2. 收缩压
            [3, 0, 0, 1, 1, 1, 1, -1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, -1, 1, 0, 1, 1, 1],
            # 3. 舒张压
            [3, 0, 0, 1, 1, 1, 1, -1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, -1, 1, 0, 1, 1, 1],
            # 4. 血糖
            [2, 0, 0, 0, 2, 1, 2, -1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, 1],
            # 5. 总胆固醇
            [2, 1, 1, 2, 0, 1, 2, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 6. LDL-C
            [2, 1, 1, 1, 1, 0, 1, -2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 7. 甘油三酯
            [3, 1, 1, 2, 2, 1, 0, -1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 8. HDL-C
            [-2, -1, -1, -1, -1, -2, -1, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 9. D-二聚体
            [1, 1, 1, 1, 1, 1, 1, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 10. 血小板
            [1, 1, 1, 1, 0, 1, 1, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 11. 中性粒细胞
            [2, 2, 2, 2, 0, 0, 2, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 12. 淋巴细胞
            [2, 1, 1, 2, 0, 0, 3, -3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 13. NLR（中性粒细胞/淋巴细胞）
            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 14. 神经元特异性烯醇化酶
            [-1, 0, 0, -1, -1, 0, -1, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, -1, 1, 0, -1, 0, -1],
            # 15. 鳞状细胞癌相关抗原
            [-1, 0, 0, -1, -1, 0, -1, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, -1, 1, 0, 1, -1, 1],
            # 16. 胃泌素释放肽前体
            [-1, 0, 0, -1, -1, 0, -1, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, -1, 1, 0, -1, 0, -1],
            # 17. 细胞角蛋白19片段
            [-1, 0, 0, -1, -1, 0, -1, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, -1, 1, 0, 1, -1, 1],
            # 18. CRP
            [2, 1, 1, 1, 1, 1, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],
            # 19. 降钙素原
            [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 20. IL-6
            [2, 1, 1, 1, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 21. BNP
            [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 22. 高敏肌钙蛋白T
            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 23. 肾小球滤过率
            [0, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 24. 肌酐
            [0, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 25. 脂蛋白a
            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            # 26. 游离三碘甲状腺原氨酸
            [-1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, -2, 1],
            # 27. 促甲状腺激素
            [1, 1, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],
            # 28. 游离甲状腺素
            [-2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, -2, 0]
        ]
        adj = torch.FloatTensor(adj_data)
        adj = adj / 3.0  # 缩小到 [-1, 1] 范围

        adj_expert = torch.FloatTensor(adj_data_expert)
        adj_expert = adj_expert / 3.0  # 缩小到 [-1, 1] 范围
        return adj*0.4+adj_expert*0.6

    # # 把邻接矩阵改为单位矩阵,做去掉医学知识的消融实验
    # def build_adj(self):
    #     # 直接返回单位矩阵（对角线为1，其余为0）
    #     adj = torch.eye(NUM_IND, device=self.phys_gcn.fc1.weight.device)
    #     return adj  # 或者 adj * 1.0 保持 float 类型

    def forward(
            self,
            phys_values,  # B × V
            last_treat_types,  # list[str] 長度 B
            delta_t,  # B
            treat_events,  # list[list[dict]]
            current_time,  # B
            time_idx  # B
    ):
        B = phys_values.size(0)

        # 治療效應調整（不變）
        acute = self.acute_module(last_treat_types, delta_t)  # B × V
        cum = torch.stack([self.cum_module(treat_events[b], current_time[b])
                           for b in range(B)], dim=0)  # B × V
        phys_values_adj = phys_values + acute + cum

        # 去掉急性感知模块
        # phys_values_adj = phys_values + cum

        # # 去掉累积感知模块
        # phys_values_adj = phys_values + acute

        # 指標 embedding + GCN 傳播（不變）
        phys_emb = self.phys_encoder(phys_values_adj.unsqueeze(-1))  # B × V × E
        phys_emb = self.phys_gcn(phys_emb, self.adj)  # B × V × E

        # ───── attention pooling ─────
        pooled, weights = self.attn_pool(phys_emb)  # pooled: B × E

        # # # 替换 attention pooling 为均值池化
        # pooled = torch.mean(phys_emb, dim=1)  # B × E
        # # 如果你还想保留 weights 用于对比实验，可以手动计算均匀权重（可选）
        # weights = torch.ones(B, NUM_IND, device=phys_emb.device) / NUM_IND

        # 時間嵌入（不變）
        time_input = torch.stack([delta_t, current_time], dim=-1)  # B × 2
        time_emb = self.time_encoder(time_input)  # B × E

        # 治療事件嵌入（不變）
        treat_count = torch.zeros(B, NUM_TREAT, device=phys_values.device)
        for b in range(B):
            for ev in treat_events[b]:
                if ev['type'] in self.cum_module.treat2id:
                    tid = self.cum_module.treat2id[ev['type']]
                    treat_count[b, tid] += 1.0
        treat_emb = self.treat_embedding(treat_count)  # B × E

        # 融合三路信息
        fused = pooled + time_emb + treat_emb  # B × E

        # 最終預測
        tbr_pred = self.tbr_head(fused, time_idx)

        return {
            "tbr_pred": tbr_pred,
            "weights": weights,  # B × V  可視化每個生理指標的重要性
        }